{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Prepare Notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.1 Deleate Outdated Log Files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!rm \"log.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.2 Install Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pytorch-metric-learning\n",
    "!pip install faiss-gpu\n",
    "!pip install PyPDF2\n",
    "!pip install FPDF\n",
    "!pip install efficientnet_pytorch\n",
    "!pip install umap-learn\n",
    "!pip install gpustat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.3 Import Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from shutil import copyfile\n",
    "\n",
    "import PIL\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import umap\n",
    "from PyPDF2 import PdfFileMerger\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from fpdf import FPDF\n",
    "from google.colab import drive\n",
    "from matplotlib import rc, pyplot as plt\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers\n",
    "from pytorch_metric_learning.testers import GlobalEmbeddingSpaceTester\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "from pytorch_metric_learning.utils.inference import InferenceModel, MatchFinder\n",
    "from torchvision import transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rc('text', usetex=False)\n",
    "matplotlib.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n",
    "% matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.4 Mount Google Drive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.5 Instansiate Logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#logging.basicConfig(filename=\"test.log\", level=logging.INFO )\n",
    "logger = logging.getLogger('log')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler('log.txt')\n",
    "fh.setLevel(logging.INFO)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "fh.setFormatter(formatter)\n",
    "# add the handlers to logger\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)\n",
    "logger.propagate = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. PyTorch Definitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FAUPapyrusCollectionDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FAUPapyrusCollection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, processed_frame, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.processed_frame = processed_frame\n",
    "        self.transform = transform\n",
    "        self.targets = processed_frame[\"papyID\"].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.processed_frame.iloc[idx, 1])\n",
    "\n",
    "        img_name = img_name + '.png'\n",
    "\n",
    "        #image = io.imread(img_name , plugin='matploPILtlib')\n",
    "        image = PIL.Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        papyID = self.processed_frame.iloc[idx, 3]\n",
    "\n",
    "        return image, papyID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Architecturess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2.1 Simple CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12544, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3.1 Training-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, train_set, epoch, accuracy_calculator,\n",
    "          scheduler, accumulation_steps):\n",
    "    model.train()\n",
    "    #model.zero_grad()\n",
    "    epoch_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (input_imgs, labels) in enumerate(train_loader):\n",
    "        labels = labels.to(device)\n",
    "        input_imgs = input_imgs.to(device)\n",
    "        bs, ncrops, c, h, w = input_imgs.size()\n",
    "\n",
    "        embeddings = model(input_imgs.view(-1, c, h, w))\n",
    "        embeddings_avg = embeddings.view(bs, ncrops, -1).mean(1)\n",
    "\n",
    "        indices_tuple = mining_func(embeddings_avg, labels)\n",
    "        loss = loss_func(embeddings_avg, labels, indices_tuple)\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += embeddings_avg.shape[0] * loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    train_labels = train_labels.squeeze(1)\n",
    "\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        train_embeddings,\n",
    "        train_embeddings,\n",
    "        train_labels,\n",
    "        train_labels,\n",
    "        False)\n",
    "\n",
    "    #mean_loss = torch.mean(torch.stack(batch_loss_values))\n",
    "    logger.info(f\"Epoch {epoch} averg loss from {batch_idx} batches: {epoch_loss}\")\n",
    "    map = accuracies[\"mean_average_precision\"]\n",
    "    logger.info(f\"Eoch {epoch} maP: {map}\")\n",
    "    return epoch_loss, accuracies[\"mean_average_precision\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3.2 Validation-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def val(train_set, test_set, model, accuracy_calculator):\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "\n",
    "    train_labels = train_labels.squeeze(1)\n",
    "    test_labels = test_labels.squeeze(1)\n",
    "\n",
    "    print(\"Computing accuracy\")\n",
    "\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
    "    )\n",
    "\n",
    "    idx = torch.randperm(test_labels.nelement())\n",
    "    test_labels = test_labels.view(-1)[idx].view(test_labels.size())\n",
    "\n",
    "    random_accuracies = accuracy_calculator.get_accuracy(\n",
    "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
    "    )\n",
    "\n",
    "    map = accuracies[\"mean_average_precision\"]\n",
    "    random_map = random_accuracies[\"mean_average_precision\"]\n",
    "    logger.info(f\"Val mAP = {map}\")\n",
    "    logger.info(f\"Val random mAP) = {random_map}\")\n",
    "\n",
    "    return accuracies[\"mean_average_precision\"], random_accuracies[\"mean_average_precision\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.0. PyTorchDeepMetricLearning Definitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Test-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomTester(GlobalEmbeddingSpaceTester):\n",
    "    def get_embeddings_for_eval(self, trunk_model, embedder_model, input_imgs):\n",
    "        input_imgs = c_f.to_device(\n",
    "            input_imgs, device=self.data_device, dtype=self.dtype\n",
    "        )\n",
    "        print('yes')\n",
    "        # from https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.FiveCrop\n",
    "        bs, ncrops, c, h, w = input_imgs.size()\n",
    "        result = embedder_model(trunk_model(input_imgs.view(-1, c, h, w)))  # fuse batch size and ncrops\n",
    "        result_avg = result.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
    "        return result_avg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Visualizer-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, *args):\n",
    "    logging.info(\n",
    "        \"UMAP plot for the {} split and label set {}\".format(split_name, keyname)\n",
    "    )\n",
    "    label_set = np.unique(labels)\n",
    "    num_classes = len(label_set)\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    plt.gca().set_prop_cycle(\n",
    "        cycler(\n",
    "            \"color\", [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]\n",
    "        )\n",
    "    )\n",
    "    for i in range(num_classes):\n",
    "        idx = labels == label_set[i]\n",
    "        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=1)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. Embedding-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_embeddings(dataset, model, collate_fn=None, eval=True):\n",
    "    tester = CustomTester(visualizer=umap.UMAP(), visualizer_hook=visualizer_hook, )\n",
    "    return tester.get_all_embeddings(dataset, model, collate_fn=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.0 Python Definitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Gradient-Visualizer-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_visualization(parameters, output_path):\n",
    "    \"\"\"\n",
    "    Returns the parameter gradients over the epoch.\n",
    "    :param parameters: parameters of the network\n",
    "    :type parameters: iterator\n",
    "    :param results_folder: path to results folder\n",
    "    :type results_folder: str\n",
    "    \"\"\"\n",
    "    tex_fonts = {\n",
    "        # Use LaTeX to write all text\n",
    "        \"text.usetex\": False,\n",
    "        \"font.family\": \"serif\",\n",
    "        # Use 10pt font in plots, to match 10pt font in document\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        # Make the legend/label fonts a little smaller\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"legend.loc\": 'lower left'\n",
    "    }\n",
    "    plt.rcParams.update(tex_fonts)\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in parameters:\n",
    "        if (p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads) + 1, linewidth=1, color=\"k\")\n",
    "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient Visualization\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path + \"/gradients.pdf\")\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. Accuracy-Visualizer-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_acc(map_vals, random_map_vals, train_map, epochs, output_path):\n",
    "    width = 460\n",
    "    plt.style.use('seaborn-bright')\n",
    "    tex_fonts = {\n",
    "        # Use LaTeX to write all text\n",
    "        \"text.usetex\": False,\n",
    "        \"font.family\": \"serif\",\n",
    "        # Use 10pt font in plots, to match 10pt font in document\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        # Make the legend/label fonts a little smaller\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8\n",
    "    }\n",
    "    #linestyle='dotted'\n",
    "\n",
    "    plt.rcParams.update(tex_fonts)\n",
    "    epochs = np.arange(1, epochs + 1)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
    "    ax.plot(epochs, random_map_vals, 'r', label='random mAP')\n",
    "    ax.plot(epochs, train_map, 'g', label='train mAP')\n",
    "    ax.plot(epochs, map_vals, 'b', label='val mAP')\n",
    "    ax.set_title('Validation Accuracy')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "    fig.savefig(output_path + '/acc.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. Loss-Visualizer-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(train_loss_values, epochs, output_path):\n",
    "    width = 460\n",
    "    plt.style.use('seaborn-bright')\n",
    "    tex_fonts = {\n",
    "        # Use LaTeX to write all text\n",
    "        \"text.usetex\": False,\n",
    "        \"font.family\": \"serif\",\n",
    "        # Use 10pt font in plots, to match 10pt font in document\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        # Make the legend/label fonts a little smaller\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8\n",
    "    }\n",
    "    plt.rcParams.update(tex_fonts)\n",
    "    epochs = np.arange(1, epochs + 1)\n",
    "    train_loss_values = np.array(train_loss_values)\n",
    "    plt.style.use('seaborn')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
    "    ax.plot(epochs, train_loss_values, 'b', label='Training Loss', linestyle='dotted')\n",
    "    ax.set_title('Training')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "\n",
    "    fig.savefig(output_path + '/loss.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4. Hyperparameters-Log-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_table(setting, param, dml_param, output_path):\n",
    "    width = 460\n",
    "    plt.style.use('seaborn-bright')\n",
    "    tex_fonts = {\n",
    "        # Use LaTeX to write all text\n",
    "        \"text.usetex\": False,\n",
    "        \"font.family\": \"serif\",\n",
    "        # Use 10pt font in plots, to match 10pt font in document\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        # Make the legend/label fonts a little smaller\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8\n",
    "    }\n",
    "    plt.rcParams.update(tex_fonts)\n",
    "\n",
    "    ########## Plot Settings ##################\n",
    "    setting_name_list = list(setting.keys())\n",
    "    setting_value_list = list(setting.values())\n",
    "    setting_name_list, setting_value_list = replace_helper(setting_name_list, setting_value_list)\n",
    "    vals = np.array([setting_name_list, setting_value_list], dtype=str).T\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
    "    ax.table(cellText=vals, colLabels=['Setting', 'Value'], loc='center', zorder=3, rowLoc='left', cellLoc='left')\n",
    "    ax.set_title('Experiment Settings')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig(output_path + '/settings.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    ########## Plot Params ##################\n",
    "    param_name_list = param.keys()\n",
    "    param_value_list = param.values()\n",
    "    param_name_list, param_value_list = replace_helper(param_name_list, param_value_list)\n",
    "    param_vals = np.array([list(param_name_list), list(param_value_list)], dtype=str).T\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
    "    ax.table(cellText=param_vals, colLabels=['Hyperparameter', 'Value'], loc='center', zorder=3, rowLoc='left',\n",
    "             cellLoc='left')\n",
    "    ax.set_title('Hyperparaeters')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig(output_path + '/params.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    ########## Plot DML Params ##################\n",
    "    dml_param_name_list = dml_param.keys()\n",
    "    dml_param_value_list = dml_param.values()\n",
    "    dml_param_name_list, dml_param_value_list = replace_helper(dml_param_name_list, dml_param_value_list)\n",
    "    dml_param_vals = np.array([list(dml_param_name_list), list(dml_param_value_list)], dtype=str).T\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
    "    ax.table(cellText=dml_param_vals, colLabels=['DML Hyperparameter', 'Value'], loc='center', zorder=3, rowLoc='left',\n",
    "             cellLoc='left')\n",
    "    ax.set_title('DML Hyperparameters')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig(output_path + '/dml_params.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.5. Data-File-Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_processed_info(path, debug=False):\n",
    "    if debug:\n",
    "        info_path = join(path, 'debug_processed_info.csv')\n",
    "    else:\n",
    "        info_path = join(path, 'processed_info.csv')\n",
    "    if isfile(info_path):\n",
    "        processed_frame = pd.read_csv(info_path, index_col=0,\n",
    "                                      dtype={'fnames': str, 'papyID': int, 'posinfo': str, 'pixelCentimer': float},\n",
    "                                      header=0)\n",
    "    else:\n",
    "        fnames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        fnames = [x for x in fnames if \".png\" in x]\n",
    "        fnames = [f.split('.', 1)[0] for f in fnames]\n",
    "        fnames_frame = pd.DataFrame(fnames, columns=['fnames'])\n",
    "        fragmentID = pd.DataFrame([f.split('_', 1)[0] for f in fnames], columns=['fragmentID'])\n",
    "        fnames_raw = [f.split('_', 1)[1] for f in fnames]\n",
    "        processed_frame = pd.DataFrame(fnames_raw, columns=['fnames_raw'])\n",
    "\n",
    "        processed_frame = pd.concat([processed_frame, fnames_frame], axis=1)\n",
    "\n",
    "        processed_frame = pd.concat([processed_frame, fragmentID], axis=1)\n",
    "        processed_frame['papyID'] = processed_frame.fnames_raw.apply(lambda x: x.split('_', 1)[0])\n",
    "        processed_frame['posinfo'] = processed_frame.fnames_raw.apply(lambda x: ''.join(filter(str.isalpha, x)))\n",
    "        processed_frame['pixelCentimer'] = processed_frame.fnames_raw.progress_apply(retrive_size_by_fname)\n",
    "        processed_frame.to_csv(info_path)\n",
    "\n",
    "    return processed_frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.6. Logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.6.1 Thesis Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_size(width, fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float or string\n",
    "            Document width in points, or string of predined document type\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    if width == 'thesis':\n",
    "        width_pt = 426.79135\n",
    "    elif width == 'beamer':\n",
    "        width_pt = 307.28987\n",
    "    else:\n",
    "        width_pt = width\n",
    "\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    inches_per_pt = 1 / 72.27\n",
    "    golden_ratio = (5 ** .5 - 1) / 2\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_helper(some_list_1, some_list_2):\n",
    "    new_list_1 = []\n",
    "    new_list_2 = []\n",
    "\n",
    "    for string_a, string_b in zip(some_list_1, some_list_2):\n",
    "        new_list_1.append(str(string_a).replace(\"_\", \" \"))\n",
    "        new_list_2.append(str(string_b).replace(\"_\", \" \"))\n",
    "\n",
    "    return new_list_1, new_list_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.6.2 Dir-Management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_output_dir(name, experiment_name, x=1):\n",
    "    while True:\n",
    "        dir_name = (name + (str(x) + '_iteration_' if x is not 0 else '') + '_' + experiment_name).strip()\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "\n",
    "            return dir_name\n",
    "        else:\n",
    "            x = x + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.6.3 Report-PDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_logging(setting, param, dml_param, train_loss_values, map_vals, random_map_vals, train_map, epochs,\n",
    "                   output_dir, model):\n",
    "    plot_table(setting, param, dml_param, output_dir)\n",
    "\n",
    "    gradient_visualization(model.named_parameters(), output_dir)\n",
    "    plot_loss(train_loss_values, epochs, output_dir)\n",
    "    plot_acc(map_vals, random_map_vals, train_map, epochs, output_dir)\n",
    "\n",
    "    pdfs = ['/loss.pdf', '/acc.pdf', '/params.pdf', '/dml_params.pdf', '/settings.pdf', '/gradients.pdf']\n",
    "    bookmarks = ['Loss', 'Accuracy', 'Hyperparameters', 'DML Hyperparameters', 'Seetings', 'Gradients']\n",
    "\n",
    "    merger = PdfFileMerger()\n",
    "\n",
    "    for i, pdf in enumerate(pdfs):\n",
    "        merger.append(output_dir + pdf, bookmark=bookmarks[i])\n",
    "\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Helvetica\", size=6)\n",
    "    # open the text file in read mode\n",
    "    f = open(\"log.txt\", \"r\")\n",
    "\n",
    "    # insert the texts in pdf\n",
    "    for x in f:\n",
    "        pdf.cell(200, 6, txt=x, ln=1, align='l')\n",
    "\n",
    "        # save the pdf with name .pdf\n",
    "    pdf.output(\"log.pdf\")\n",
    "    merger.append(\"log.pdf\", bookmark='Log')\n",
    "    merger.write(output_dir + \"/report.pdf\")\n",
    "    merger.close()\n",
    "\n",
    "    copyfile('log.txt', output_dir + '/log.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.0. Initialize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1. Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = Net().to(device)\n",
    "config = toml.load('./gdrive/MyDrive/mt/conf/conf.toml')\n",
    "setting = config.get('settings')\n",
    "param = config.get('params')\n",
    "dml_param = config.get('dml_params')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2. Logging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.1. Create Dir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_dir = create_output_dir(setting['output'], setting['experiment_name'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.2. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size_train = param['batch_size_train']\n",
    "batch_size_val = param['batch_size_val']\n",
    "lr = param['lr']\n",
    "num_epochs = param['num_epochs']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.3. Optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if param['optimizer'] == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "elif param['optimizer'] == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "elif param['optimizer'] == 'AdamW':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "else:\n",
    "    logger.error(' Optimizer is not supported or you have not specified one.')\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.4. Model Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if param['archi'] == 'SimpleCNN':\n",
    "    model = Net().to(device)\n",
    "\n",
    "elif param['archi'] == 'efficientnetB0':\n",
    "    model = EfficientNet.from_name('efficientnet-b0').to(device)\n",
    "\n",
    "elif param['archi'] == 'efficientnetB7':\n",
    "    model = EfficientNet.from_name('efficientnet-b7').to(device)\n",
    "    model._fc = torch.nn.Identity()\n",
    "\n",
    "elif param['archi'] == 'densenet201':\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=False).to(device)\n",
    "    model.classifier = torch.nn.Identity()\n",
    "\n",
    "elif param['archi'] == 'ResNet':\n",
    "    model = models.resnet18(pretrained=True).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.5. Scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[12], gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3.0. PyTorch-Metric-Learning Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.1. Distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dml_param['distance'] == 'CosineSimilarity':\n",
    "    distance = distances.CosineSimilarity()\n",
    "\n",
    "elif dml_param['distance'] == 'LpDistance':\n",
    "    distance = distances.LpDistance(normalize_embeddings=True, p=2, power=1)\n",
    "\n",
    "else:\n",
    "    logger.error(' Distance is not supported or you have not specified one.')\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.2. Reducer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dml_param['reducer'] == 'ThresholdReducer':\n",
    "    reducer = reducers.ThresholdReducer(low=dml_param['ThresholdReducer_low'])\n",
    "\n",
    "elif dml_param['reducer'] == 'AvgNonZeroReducer':\n",
    "    reducer = reducers.AvgNonZeroReducer()\n",
    "\n",
    "else:\n",
    "    logger.error(f'Reducer is not supported or you have not specified one.')\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.3. Los Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dml_param['loss_function'] == 'TripletMarginLoss':\n",
    "    loss_func = losses.TripletMarginLoss(margin=dml_param['TripletMarginLoss_margin'], distance=distance,\n",
    "                                         reducer=reducer)\n",
    "\n",
    "elif dml_param['loss_function'] == 'ContrastiveLoss':\n",
    "    loss_func = losses.ContrastiveLoss(pos_margin=1, neg_margin=0)\n",
    "\n",
    "elif dml_param['loss_function'] == 'CircleLoss':\n",
    "    loss_func = losses.CircleLoss(m=dml_param['m'], gamma=dml_param['gamma'], distance=distance, reducer=reducer)\n",
    "\n",
    "else:\n",
    "    logger.error('DML Loss is not supported or you have not specified one.')\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.4. Mining Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dml_param['miner'] == 'TripletMarginMiner':\n",
    "    mining_func = miners.TripletMarginMiner(\n",
    "        margin=dml_param['TripletMarginMiner_margin'],\n",
    "        distance=distance,\n",
    "        type_of_triplets=dml_param['type_of_triplets']\n",
    "    )\n",
    "\n",
    "else:\n",
    "    logger.error('DML Miner is not supported or you have not specified one.')\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.5. Accuracy Calculator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_calculator = AccuracyCalculator(include=(dml_param['metric_1'],\n",
    "                                                  dml_param['metric_2']),\n",
    "                                         k=dml_param['precision_at_1_k'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4.0.Transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.1. PyTorch-Transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.TenCrop((param['crop_1'], param['crop_2'])),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.PILToTensor()(crop) for crop in crops])),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((param['normalize_1'], param['normalize_2'], param['normalize_3']),\n",
    "                         (param['normalize_4'], param['normalize_5'], param['normalize_6']))]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.TenCrop((param['crop_1'], param['crop_2'])),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.PILToTensor()(crop) for crop in crops])),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((param['normalize_1'], param['normalize_2'], param['normalize_3']),\n",
    "                         (param['normalize_4'], param['normalize_5'], param['normalize_6']))]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4.0 Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.1 Get File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_frame_train = create_processed_info(setting['path_train'])\n",
    "processed_frame_val = create_processed_info(setting['path_val'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.2 Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = FAUPapyrusCollectionDataset(setting['path_train'], processed_frame_train, train_transform)\n",
    "val_dataset = FAUPapyrusCollectionDataset(setting['path_val'], processed_frame_val, val_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.3 Init Data Loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, drop_last=True,\n",
    "                                           num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size_val, drop_last=True, num_workers=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.4. Create Empty Result Lists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_vals = []\n",
    "val_loss_vals = []\n",
    "map_vals = []\n",
    "random_map_vals = []\n",
    "train_map_vals = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.0. raining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1. Log Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger.info(f'Debug:                {setting[\"debug\"]}')\n",
    "logger.info(f'Loos Function:        {dml_param[\"loss_function\"]}')\n",
    "logger.info(f'Margin Miner Margin:  {dml_param[\"TripletMarginMiner_margin\"]}')\n",
    "logger.info(f'Triplet Margin Loss:  {dml_param[\"TripletMarginLoss_margin\"]}')\n",
    "logger.info(f'Type of Tribles:      {dml_param[\"type_of_triplets\"]}')\n",
    "logger.info(f'Miner:                {dml_param[\"miner\"]}')\n",
    "logger.info(f'Reducer:              {dml_param[\"reducer\"]}')\n",
    "logger.info(f'Archi:                {param[\"archi\"]}')\n",
    "logger.info(f'Epochs:               {param[\"num_epochs\"]}')\n",
    "logger.info(f'Batch Size Train:     {param[\"batch_size_train\"]}')\n",
    "logger.info(f'Batch Size Val:       {param[\"batch_size_val\"]}')\n",
    "logger.info(f'Optimizer:            {param[\"optimizer\"]}')\n",
    "logger.info(f'Learning Rate:        {param[\"lr\"]}')\n",
    "logger.info(f'Shuffle:              {param[\"shuffle\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2. Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def start_training():\n",
    "    old_map = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        ############### Training ###############\n",
    "        train_loss, train_map = train(\n",
    "            model,\n",
    "            loss_func, mining_func,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            train_dataset,\n",
    "            epoch,\n",
    "            accuracy_calculator,\n",
    "            scheduler,\n",
    "            accumulation_steps=param['accumulation_steps']\n",
    "        )\n",
    "\n",
    "        ############### Validation ###############\n",
    "        map, random_map = val(val_dataset, val_dataset, model, accuracy_calculator)\n",
    "\n",
    "        ############### Fill Lists ###############\n",
    "        loss_vals.append(train_loss)\n",
    "        map_vals.append(map)\n",
    "        random_map_vals.append(random_map)\n",
    "        train_map_vals.append(train_map)\n",
    "        ############### Checkpoint ###############\n",
    "\n",
    "        if map >= old_map:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': train_loss,\n",
    "            }, output_dir + \"/model.pt\")\n",
    "\n",
    "        old_map = map\n",
    "        ############### Logging ###############\n",
    "        create_logging(setting, param, dml_param, loss_vals, map_vals, random_map_vals, train_map_vals, epoch,\n",
    "                       output_dir, model)\n",
    "\n",
    "\n",
    "if setting[\"training\"]:\n",
    "    start_training()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.0. Inference\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1. Helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_decision(is_match):\n",
    "    if is_match:\n",
    "        print(\"Same class\")\n",
    "    else:\n",
    "        print(\"Different class\")\n",
    "\n",
    "\n",
    "mean = [0.6143, 0.6884, 0.7665]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-m / s for m, s in zip(mean, std)], std=[1 / s for s in std]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def imshow(img, figsize=(21, 9), boarder=None, get_img=False):\n",
    "    img = inv_normalize(img)\n",
    "    BLUE = [255, 0, 0]\n",
    "    npimg = img.numpy()\n",
    "    transposed = np.transpose(npimg, (1, 2, 0))\n",
    "    #boarderized = draw_border(transposed, bt=5, with_plot=False, gray_scale=False, color_name=\"red\")\n",
    "    x = int(transposed.shape[1] * 0.025)\n",
    "    y = int(transposed.shape[2] * 0.025)\n",
    "    if x > y:\n",
    "        y = x\n",
    "    else:\n",
    "        y = x\n",
    "\n",
    "    if boarder == 'green':\n",
    "        boarderized = cv2.copyMakeBorder(transposed, x, x, y, y, cv2.BORDER_CONSTANT, value=[0, 255, 0])\n",
    "    elif boarder == 'red':\n",
    "        boarderized = cv2.copyMakeBorder(transposed, x, x, y, y, cv2.BORDER_CONSTANT, value=[255, 0, 0])\n",
    "    else:\n",
    "        boarderized = transposed\n",
    "    if get_img:\n",
    "        return boarderized\n",
    "    else:\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow((boarderized * 255).astype(np.uint8))\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3. Initilize Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FAUPapyrusCollectionInferenceDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"FAUPapyrusCollection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, processed_frame, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.processed_frame = processed_frame\n",
    "        self.transform = transform\n",
    "        self.targets = processed_frame[\"papyID\"].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.processed_frame.iloc[idx, 1])\n",
    "\n",
    "        img_name = img_name + '.png'\n",
    "\n",
    "        #image = io.imread(img_name , plugin='matploPILtlib')\n",
    "        image = PIL.Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        #if False:\n",
    "        max_img_size = 2048\n",
    "\n",
    "        if (image.shape[1] > max_img_size) or (image.shape[2] > max_img_size):\n",
    "            image = transforms.CenterCrop(max_img_size)(image)\n",
    "\n",
    "        papyID = self.processed_frame.iloc[idx, 3]\n",
    "\n",
    "        return image, papyID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyInferenceModel(InferenceModel):\n",
    "\n",
    "    def get_embeddings_from_tensor_or_dataset(self, inputs, batch_size):\n",
    "        inputs = self.process_if_list(inputs)\n",
    "        embeddings = []\n",
    "        if isinstance(inputs, (torch.Tensor, list)):\n",
    "            for i in range(0, len(inputs), batch_size):\n",
    "                embeddings.append(self.get_embeddings(inputs[i: i + batch_size]))\n",
    "        elif isinstance(inputs, torch.utils.data.Dataset):\n",
    "            dataloader = torch.utils.data.DataLoader(inputs, batch_size=batch_size)\n",
    "            for inp, _ in dataloader:\n",
    "                embeddings.append(self.get_embeddings(inp))\n",
    "        else:\n",
    "            raise TypeError(f\"Indexing {type(inputs)} is not supported.\")\n",
    "        return torch.cat(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = FAUPapyrusCollectionInferenceDataset(setting['path_val'], processed_frame_val, transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3. Get Indices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_labels_to_indices(dataset):\n",
    "    labels_to_indices = {}\n",
    "    for i, sample in enumerate(dataset):\n",
    "        img, label = sample\n",
    "        if label in labels_to_indices.keys():\n",
    "            labels_to_indices[label].append(i)\n",
    "        else:\n",
    "            labels_to_indices[label] = [i]\n",
    "    return labels_to_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_to_indices = get_labels_to_indices(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.4. Load Checkpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model = EfficientNet.from_name('efficientnet-b7').to(device)\n",
    "model._fc = torch.nn.Identity()\n",
    "checkpoint = torch.load(output_dir + \"/model.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5. Create Inference Model and Match Finder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "match_finder = MatchFinder(distance=distances.CosineSimilarity(), threshold=0.2)\n",
    "inference_model = InferenceModel(model, match_finder=match_finder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.6. Retrain Knn for Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inference_model.train_knn(dataset, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Infercening"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if setting['inference']:\n",
    "    k = 100\n",
    "\n",
    "    lowest_acc = 1\n",
    "    highest_acc = 0\n",
    "\n",
    "    temp_counter = 0\n",
    "\n",
    "    for papyID in labels_to_indices.keys():\n",
    "        if temp_counter >= 3:\n",
    "            break\n",
    "\n",
    "        for fragment in labels_to_indices[papyID]:\n",
    "            if temp_counter >= 3:\n",
    "                break\n",
    "            temp_counter = temp_counter + 1\n",
    "            img, org_label = dataset[fragment]\n",
    "            img = img.unsqueeze(0)\n",
    "            #print(f\"query image: {org_label}\")\n",
    "            #imshow(torchvision.utils.make_grid(img))\n",
    "            distances, indices = inference_model.get_nearest_neighbors(img, k=k)\n",
    "            #print(len(distances[0]))\n",
    "\n",
    "            nearest_imgs = [dataset[i][0] for i in indices.cpu()[0]]\n",
    "            #print(f\"Nearest Images:\\n\")\n",
    "\n",
    "            neighbours = []\n",
    "            labels = []\n",
    "            for i in indices.cpu()[0]:\n",
    "                neighbour, label = dataset[i]\n",
    "\n",
    "                #print(f\"Label: {label}\")\n",
    "                neighbours.append(neighbour)\n",
    "                labels.append(label)\n",
    "\n",
    "            occurrences = labels.count(org_label)\n",
    "            acc = occurrences / 100\n",
    "\n",
    "            if acc < lowest_acc:\n",
    "                lowest_acc = acc\n",
    "                print(f'Found new lowest example with acc {acc}')\n",
    "                input_img_of_lowest_acc = img\n",
    "                input_label_of_lowest_acc = org_label\n",
    "                input_index_of_lowest_acc = fragment\n",
    "                detected_neighbours_of_lowest_acc = neighbours\n",
    "                detected_labels_of_lowest_acc = labels\n",
    "                detected_distances_of_lowest_acc = distances\n",
    "\n",
    "            if acc > highest_acc:\n",
    "                highest_acc = acc\n",
    "                print(f'Found new highest example with acc {acc}')\n",
    "                input_img_of_highest_acc = img\n",
    "                input_label_of_highest_acc = org_label\n",
    "                input_index_of_highest_acc = fragment\n",
    "                detected_neighbours_of_highest_acc = neighbours\n",
    "                detected_labels_of_highest_acc = labels\n",
    "                detected_distances_of_highest_acc = distances\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_inference_plot(neighbours, labels, distances, org_label, img, k, lowest):\n",
    "    if lowest:\n",
    "        print(f\"query image for lowest acc: {org_label}\")\n",
    "    else:\n",
    "        print(f\"query image for highest acc: {org_label}\")\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(img))\n",
    "\n",
    "    Nr = k\n",
    "    Nc = 10\n",
    "    my_dpi = 96\n",
    "    fig, axs = plt.subplots(Nr, Nc)\n",
    "    fig.set_figheight(320)\n",
    "    fig.set_figwidth(30)\n",
    "    fig.suptitle(f'Neighbour Crops of {org_label}')\n",
    "\n",
    "    for i, neighbour in enumerate(neighbours):\n",
    "        neighbour_crops = transforms.TenCrop(32)(neighbour)\n",
    "        for j in range(Nc):\n",
    "            if j == 0:\n",
    "                distance = (distances[i].cpu().numpy().round(2))\n",
    "\n",
    "                row_label = f\"label: {labels[i]} \\n distance: {distance}\"\n",
    "                axs[i, j].set_ylabel(row_label)\n",
    "\n",
    "            neighbour_crop = neighbour_crops[j]\n",
    "            img = inv_normalize(neighbour_crop)\n",
    "            npimg = img.numpy()\n",
    "            transposed = np.transpose(npimg, (1, 2, 0))\n",
    "\n",
    "            # find right size for the frame\n",
    "            x = int(transposed.shape[1] * 0.05)\n",
    "\n",
    "            boarder = 'green'\n",
    "\n",
    "            if org_label == labels[i]:\n",
    "                boarderized = cv2.copyMakeBorder(transposed, x, x, x, x, cv2.BORDER_CONSTANT, value=[0, 1, 0])\n",
    "            elif org_label != labels[i]:\n",
    "                boarderized = cv2.copyMakeBorder(transposed, x, x, x, x, cv2.BORDER_CONSTANT, value=[1, 0, 0])\n",
    "            else:\n",
    "                boarderized = transposed\n",
    "\n",
    "            axs[i, j].imshow(boarderized, aspect='auto')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if lowest:\n",
    "        plt.savefig(\"results_for_highest_acc.pdf\", bbox_inches='tight', dpi=100)\n",
    "    else:\n",
    "        plt.savefig(\"results_for_highest_acc.pdf\", bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#get_inference_plot(neighbours, labels, distances[0], org_label, img, k=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if setting['inference']:\n",
    "    get_inference_plot(detected_neighbours_of_highest_acc, detected_labels_of_highest_acc,\n",
    "                       detected_distances_of_highest_acc[0], input_label_of_highest_acc, input_img_of_highest_acc,\n",
    "                       k=100, lowest=False)\n",
    "    get_inference_plot(detected_neighbours_of_lowest_acc, detected_labels_of_lowest_acc,\n",
    "                       detected_distances_of_lowest_acc[0], input_label_of_lowest_acc, input_img_of_lowest_acc, k=100,\n",
    "                       lowest=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "0.2.8-tb-train.ipynb",
   "provenance": [
    {
     "file_id": "1Z2JtGH4D5G0mJ-E0mQDajoMGMAbXoC57",
     "timestamp": 1642662878145
    },
    {
     "file_id": "1izhDpKHanssbTmxUu7EVRYCOxB8f5PIs",
     "timestamp": 1641988891616
    },
    {
     "file_id": "1gxDBBsWnotCl1C00l-vxh5E7mcmkZ4wT",
     "timestamp": 1640081619510
    },
    {
     "file_id": "10u_u0_osI6y5JviWcnWhh9ihCFP-4JX8",
     "timestamp": 1639748676495
    },
    {
     "file_id": "13yQSmVzddAa7-qxOEUtEX3Tt89I6ETpV",
     "timestamp": 1639677526935
    },
    {
     "file_id": "https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/TripletMarginLossMNIST.ipynb",
     "timestamp": 1639668015260
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}