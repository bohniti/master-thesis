{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bohniti/master-thesis/blob/main/notebooks/training/0.2.8-tb-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Prepare Notebook"
      ],
      "metadata": {
        "collapsed": false,
        "id": "NZmbKhsXrh82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.1 Deleate Outdated Log Files"
      ],
      "metadata": {
        "collapsed": false,
        "id": "8i10QYWMrh85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!rm \"log.txt\""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pC7CALdcrh86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2 Install Dependencies"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3N1CmgTxrh87"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu\n",
        "!pip install PyPDF2\n",
        "!pip install FPDF\n",
        "!pip install efficientnet_pytorch\n",
        "!pip install umap-learn\n",
        "!pip install gpustat"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gkaDVx2trh87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.3 Import Dependencies"
      ],
      "metadata": {
        "collapsed": false,
        "id": "DraWZT7qrh88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "from shutil import copyfile\n",
        "\n",
        "import PIL\n",
        "import cv2\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import toml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import umap\n",
        "from PyPDF2 import PdfFileMerger\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from fpdf import FPDF\n",
        "from google.colab import drive\n",
        "from matplotlib import rc, pyplot as plt\n",
        "from pytorch_metric_learning import distances, losses, miners, reducers\n",
        "from pytorch_metric_learning.testers import GlobalEmbeddingSpaceTester\n",
        "from pytorch_metric_learning.utils import common_functions as c_f\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "from pytorch_metric_learning.utils.inference import InferenceModel, MatchFinder\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cSvmkch5rh88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "rc('text', usetex=False)\n",
        "matplotlib.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n",
        "% matplotlib inline"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7_w-2fFcrh89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.4 Mount Google Drive"
      ],
      "metadata": {
        "collapsed": false,
        "id": "wBypy98drh8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NFiAVwtmrh8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.5 Instansiate Logger"
      ],
      "metadata": {
        "collapsed": false,
        "id": "PUQq4z8rrh8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#logging.basicConfig(filename=\"test.log\", level=logging.INFO )\n",
        "logger = logging.getLogger('log')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "# create file handler which logs even debug messages\n",
        "fh = logging.FileHandler('log.txt')\n",
        "fh.setLevel(logging.INFO)\n",
        "# create console handler with a higher log level\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.INFO)\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "fh.setFormatter(formatter)\n",
        "# add the handlers to logger\n",
        "logger.addHandler(ch)\n",
        "logger.addHandler(fh)\n",
        "logger.propagate = False"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-Rs-0vMrrh8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PyTorch Definitions"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ppOMNszvrh8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qigpi-e5rh8_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class FAUPapyrusCollectionDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"FAUPapyrusCollection dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, processed_frame, transform=None):\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.processed_frame = processed_frame\n",
        "        self.transform = transform\n",
        "        self.targets = processed_frame[\"papyID\"].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.processed_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.processed_frame.iloc[idx, 1])\n",
        "\n",
        "        img_name = img_name + '.png'\n",
        "\n",
        "        #image = io.imread(img_name , plugin='matploPILtlib')\n",
        "        image = PIL.Image.open(img_name)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        papyID = self.processed_frame.iloc[idx, 3]\n",
        "\n",
        "        return image, papyID"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FptyW7HBrh9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Architecturess"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lnmLeiO9rh9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 Simple CNN"
      ],
      "metadata": {
        "collapsed": false,
        "id": "BQLsbmaZrh9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(12544, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7LhCEZE5rh9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Functions"
      ],
      "metadata": {
        "collapsed": false,
        "id": "dNvu3XO2rh9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.1 Training-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7-PW_sp8rh9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train(model, loss_func, mining_func, device, train_loader, optimizer, train_set, epoch, accuracy_calculator,\n",
        "          scheduler, accumulation_steps):\n",
        "    model.train()\n",
        "    #model.zero_grad()\n",
        "    epoch_loss = 0.0\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (input_imgs, labels) in enumerate(train_loader):\n",
        "        labels = labels.to(device)\n",
        "        input_imgs = input_imgs.to(device)\n",
        "        bs, ncrops, c, h, w = input_imgs.size()\n",
        "\n",
        "        embeddings = model(input_imgs.view(-1, c, h, w))\n",
        "        embeddings_avg = embeddings.view(bs, ncrops, -1).mean(1)\n",
        "\n",
        "        indices_tuple = mining_func(embeddings_avg, labels)\n",
        "        loss = loss_func(embeddings_avg, labels, indices_tuple)\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += embeddings_avg.shape[0] * loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
        "    train_labels = train_labels.squeeze(1)\n",
        "\n",
        "    accuracies = accuracy_calculator.get_accuracy(\n",
        "        train_embeddings,\n",
        "        train_embeddings,\n",
        "        train_labels,\n",
        "        train_labels,\n",
        "        False)\n",
        "\n",
        "    #mean_loss = torch.mean(torch.stack(batch_loss_values))\n",
        "    logger.info(f\"Epoch {epoch} averg loss from {batch_idx} batches: {epoch_loss}\")\n",
        "    map = accuracies[\"mean_average_precision\"]\n",
        "    logger.info(f\"Eoch {epoch} maP: {map}\")\n",
        "    return epoch_loss, accuracies[\"mean_average_precision\"]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-ffU5ndwrh9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.2 Validation-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zSpEb5ELrh9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def val(train_set, test_set, model, accuracy_calculator):\n",
        "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
        "\n",
        "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
        "\n",
        "    train_labels = train_labels.squeeze(1)\n",
        "    test_labels = test_labels.squeeze(1)\n",
        "\n",
        "    print(\"Computing accuracy\")\n",
        "\n",
        "    accuracies = accuracy_calculator.get_accuracy(\n",
        "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
        "    )\n",
        "\n",
        "    idx = torch.randperm(test_labels.nelement())\n",
        "    test_labels = test_labels.view(-1)[idx].view(test_labels.size())\n",
        "\n",
        "    random_accuracies = accuracy_calculator.get_accuracy(\n",
        "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
        "    )\n",
        "\n",
        "    map = accuracies[\"mean_average_precision\"]\n",
        "    random_map = random_accuracies[\"mean_average_precision\"]\n",
        "    logger.info(f\"Val mAP = {map}\")\n",
        "    logger.info(f\"Val random mAP) = {random_map}\")\n",
        "\n",
        "    return accuracies[\"mean_average_precision\"], random_accuracies[\"mean_average_precision\"]\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "S7Grw3s_rh9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. PyTorchDeepMetricLearning Definitions"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Y4A_uE0nrh9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Test-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "QioUXJZXrh9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class CustomTester(GlobalEmbeddingSpaceTester):\n",
        "    def get_embeddings_for_eval(self, trunk_model, embedder_model, input_imgs):\n",
        "        input_imgs = c_f.to_device(\n",
        "            input_imgs, device=self.data_device, dtype=self.dtype\n",
        "        )\n",
        "        print('yes')\n",
        "        # from https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.FiveCrop\n",
        "        bs, ncrops, c, h, w = input_imgs.size()\n",
        "        result = embedder_model(trunk_model(input_imgs.view(-1, c, h, w)))  # fuse batch size and ncrops\n",
        "        result_avg = result.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
        "        return result_avg"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CESy6lgPrh9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Visualizer-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "M2ETkQCxrh9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, *args):\n",
        "    logging.info(\n",
        "        \"UMAP plot for the {} split and label set {}\".format(split_name, keyname)\n",
        "    )\n",
        "    label_set = np.unique(labels)\n",
        "    num_classes = len(label_set)\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    plt.gca().set_prop_cycle(\n",
        "        cycler(\n",
        "            \"color\", [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]\n",
        "        )\n",
        "    )\n",
        "    for i in range(num_classes):\n",
        "        idx = labels == label_set[i]\n",
        "        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=1)\n",
        "    plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YO1ElJLTrh9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Embedding-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Mvt-2qahrh9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_all_embeddings(dataset, model, collate_fn=None, eval=True):\n",
        "    tester = CustomTester(visualizer=umap.UMAP(), visualizer_hook=visualizer_hook, )\n",
        "    return tester.get_all_embeddings(dataset, model, collate_fn=None)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PX97or6srh9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Python Definitions"
      ],
      "metadata": {
        "collapsed": false,
        "id": "HqkXsjFVrh9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Gradient-Visualizer-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Jnils5eQrh9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def gradient_visualization(parameters, output_path):\n",
        "    \"\"\"\n",
        "    Returns the parameter gradients over the epoch.\n",
        "    :param parameters: parameters of the network\n",
        "    :type parameters: iterator\n",
        "    :param results_folder: path to results folder\n",
        "    :type results_folder: str\n",
        "    \"\"\"\n",
        "    tex_fonts = {\n",
        "        # Use LaTeX to write all text\n",
        "        \"text.usetex\": False,\n",
        "        \"font.family\": \"serif\",\n",
        "        # Use 10pt font in plots, to match 10pt font in document\n",
        "        \"axes.labelsize\": 10,\n",
        "        \"font.size\": 10,\n",
        "        # Make the legend/label fonts a little smaller\n",
        "        \"legend.fontsize\": 8,\n",
        "        \"xtick.labelsize\": 8,\n",
        "        \"ytick.labelsize\": 8,\n",
        "        \"legend.loc\": 'lower left'\n",
        "    }\n",
        "    plt.rcParams.update(tex_fonts)\n",
        "    ave_grads = []\n",
        "    layers = []\n",
        "    for n, p in parameters:\n",
        "        if (p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads) + 1, linewidth=1, color=\"k\")\n",
        "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient Visualization\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path + \"/gradients.pdf\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZtSC3Hrurh9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Accuracy-Visualizer-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "LOT8tOUtrh9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_acc(map_vals, random_map_vals, train_map, epochs, output_path):\n",
        "    width = 460\n",
        "    plt.style.use('seaborn-bright')\n",
        "    tex_fonts = {\n",
        "        # Use LaTeX to write all text\n",
        "        \"text.usetex\": False,\n",
        "        \"font.family\": \"serif\",\n",
        "        # Use 10pt font in plots, to match 10pt font in document\n",
        "        \"axes.labelsize\": 10,\n",
        "        \"font.size\": 10,\n",
        "        # Make the legend/label fonts a little smaller\n",
        "        \"legend.fontsize\": 8,\n",
        "        \"xtick.labelsize\": 8,\n",
        "        \"ytick.labelsize\": 8\n",
        "    }\n",
        "    #linestyle='dotted'\n",
        "\n",
        "    plt.rcParams.update(tex_fonts)\n",
        "    epochs = np.arange(1, epochs + 1)\n",
        "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
        "    ax.plot(epochs, random_map_vals, 'r', label='random mAP')\n",
        "    ax.plot(epochs, train_map, 'g', label='train mAP')\n",
        "    ax.plot(epochs, map_vals, 'b', label='val mAP')\n",
        "    ax.set_title('Validation Accuracy')\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.legend()\n",
        "    fig.savefig(output_path + '/acc.pdf', format='pdf', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zCb09RB5rh9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Loss-Visualizer-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Nzh66BhUrh9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_loss(train_loss_values, epochs, output_path):\n",
        "    width = 460\n",
        "    plt.style.use('seaborn-bright')\n",
        "    tex_fonts = {\n",
        "        # Use LaTeX to write all text\n",
        "        \"text.usetex\": False,\n",
        "        \"font.family\": \"serif\",\n",
        "        # Use 10pt font in plots, to match 10pt font in document\n",
        "        \"axes.labelsize\": 10,\n",
        "        \"font.size\": 10,\n",
        "        # Make the legend/label fonts a little smaller\n",
        "        \"legend.fontsize\": 8,\n",
        "        \"xtick.labelsize\": 8,\n",
        "        \"ytick.labelsize\": 8\n",
        "    }\n",
        "    plt.rcParams.update(tex_fonts)\n",
        "    epochs = np.arange(1, epochs + 1)\n",
        "    train_loss_values = np.array(train_loss_values)\n",
        "    plt.style.use('seaborn')\n",
        "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
        "    ax.plot(epochs, train_loss_values, 'b', label='Training Loss', linestyle='dotted')\n",
        "    ax.set_title('Training')\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.legend()\n",
        "\n",
        "    fig.savefig(output_path + '/loss.pdf', format='pdf', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YH4OT97vrh9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Hyperparameters-Log-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "XiNRRgNtrh9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_table(setting, param, dml_param, output_path):\n",
        "    width = 460\n",
        "    plt.style.use('seaborn-bright')\n",
        "    tex_fonts = {\n",
        "        # Use LaTeX to write all text\n",
        "        \"text.usetex\": False,\n",
        "        \"font.family\": \"serif\",\n",
        "        # Use 10pt font in plots, to match 10pt font in document\n",
        "        \"axes.labelsize\": 10,\n",
        "        \"font.size\": 10,\n",
        "        # Make the legend/label fonts a little smaller\n",
        "        \"legend.fontsize\": 8,\n",
        "        \"xtick.labelsize\": 8,\n",
        "        \"ytick.labelsize\": 8\n",
        "    }\n",
        "    plt.rcParams.update(tex_fonts)\n",
        "\n",
        "    ########## Plot Settings ##################\n",
        "    setting_name_list = list(setting.keys())\n",
        "    setting_value_list = list(setting.values())\n",
        "    setting_name_list, setting_value_list = replace_helper(setting_name_list, setting_value_list)\n",
        "    vals = np.array([setting_name_list, setting_value_list], dtype=str).T\n",
        "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
        "    ax.table(cellText=vals, colLabels=['Setting', 'Value'], loc='center', zorder=3, rowLoc='left', cellLoc='left')\n",
        "    ax.set_title('Experiment Settings')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    fig.savefig(output_path + '/settings.pdf', format='pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    ########## Plot Params ##################\n",
        "    param_name_list = param.keys()\n",
        "    param_value_list = param.values()\n",
        "    param_name_list, param_value_list = replace_helper(param_name_list, param_value_list)\n",
        "    param_vals = np.array([list(param_name_list), list(param_value_list)], dtype=str).T\n",
        "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
        "    ax.table(cellText=param_vals, colLabels=['Hyperparameter', 'Value'], loc='center', zorder=3, rowLoc='left',\n",
        "             cellLoc='left')\n",
        "    ax.set_title('Hyperparaeters')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    fig.savefig(output_path + '/params.pdf', format='pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    ########## Plot DML Params ##################\n",
        "    dml_param_name_list = dml_param.keys()\n",
        "    dml_param_value_list = dml_param.values()\n",
        "    dml_param_name_list, dml_param_value_list = replace_helper(dml_param_name_list, dml_param_value_list)\n",
        "    dml_param_vals = np.array([list(dml_param_name_list), list(dml_param_value_list)], dtype=str).T\n",
        "    fig, ax = plt.subplots(1, 1, figsize=set_size(width))\n",
        "    ax.table(cellText=dml_param_vals, colLabels=['DML Hyperparameter', 'Value'], loc='center', zorder=3, rowLoc='left',\n",
        "             cellLoc='left')\n",
        "    ax.set_title('DML Hyperparameters')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    fig.savefig(output_path + '/dml_params.pdf', format='pdf', bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UHkZg31-rh9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5. Data-File-Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "88JWxaEtrh9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_processed_info(path, debug=False):\n",
        "    if debug:\n",
        "        info_path = join(path, 'debug_processed_info.csv')\n",
        "    else:\n",
        "        info_path = join(path, 'processed_info.csv')\n",
        "    if isfile(info_path):\n",
        "        processed_frame = pd.read_csv(info_path, index_col=0,\n",
        "                                      dtype={'fnames': str, 'papyID': int, 'posinfo': str, 'pixelCentimer': float},\n",
        "                                      header=0)\n",
        "    else:\n",
        "        fnames = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "        fnames = [x for x in fnames if \".png\" in x]\n",
        "        fnames = [f.split('.', 1)[0] for f in fnames]\n",
        "        fnames_frame = pd.DataFrame(fnames, columns=['fnames'])\n",
        "        fragmentID = pd.DataFrame([f.split('_', 1)[0] for f in fnames], columns=['fragmentID'])\n",
        "        fnames_raw = [f.split('_', 1)[1] for f in fnames]\n",
        "        processed_frame = pd.DataFrame(fnames_raw, columns=['fnames_raw'])\n",
        "\n",
        "        processed_frame = pd.concat([processed_frame, fnames_frame], axis=1)\n",
        "\n",
        "        processed_frame = pd.concat([processed_frame, fragmentID], axis=1)\n",
        "        processed_frame['papyID'] = processed_frame.fnames_raw.apply(lambda x: x.split('_', 1)[0])\n",
        "        processed_frame['posinfo'] = processed_frame.fnames_raw.apply(lambda x: ''.join(filter(str.isalpha, x)))\n",
        "        processed_frame['pixelCentimer'] = processed_frame.fnames_raw.progress_apply(retrive_size_by_fname)\n",
        "        processed_frame.to_csv(info_path)\n",
        "\n",
        "    return processed_frame"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YqGxm2dOrh9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6. Logging"
      ],
      "metadata": {
        "collapsed": false,
        "id": "QEJUP9V6rh9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6.1 Thesis Settings"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ljjT7l7Zrh9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def set_size(width, fraction=1, subplots=(1, 1)):\n",
        "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    width: float or string\n",
        "            Document width in points, or string of predined document type\n",
        "    fraction: float, optional\n",
        "            Fraction of the width which you wish the figure to occupy\n",
        "    subplots: array-like, optional\n",
        "            The number of rows and columns of subplots.\n",
        "    Returns\n",
        "    -------\n",
        "    fig_dim: tuple\n",
        "            Dimensions of figure in inches\n",
        "    \"\"\"\n",
        "    if width == 'thesis':\n",
        "        width_pt = 426.79135\n",
        "    elif width == 'beamer':\n",
        "        width_pt = 307.28987\n",
        "    else:\n",
        "        width_pt = width\n",
        "\n",
        "    fig_width_pt = width_pt * fraction\n",
        "    inches_per_pt = 1 / 72.27\n",
        "    golden_ratio = (5 ** .5 - 1) / 2\n",
        "    fig_width_in = fig_width_pt * inches_per_pt\n",
        "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
        "\n",
        "    return (fig_width_in, fig_height_in)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4Lzz08BWrh9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def replace_helper(some_list_1, some_list_2):\n",
        "    new_list_1 = []\n",
        "    new_list_2 = []\n",
        "\n",
        "    for string_a, string_b in zip(some_list_1, some_list_2):\n",
        "        new_list_1.append(str(string_a).replace(\"_\", \" \"))\n",
        "        new_list_2.append(str(string_b).replace(\"_\", \" \"))\n",
        "\n",
        "    return new_list_1, new_list_2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ottbltlDrh9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.6.2 Dir-Management"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JKp_uSsZrh9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_output_dir(name, experiment_name, x=1):\n",
        "    while True:\n",
        "        dir_name = (name + (str(x) + '_iteration_' if x is not 0 else '') + '_' + experiment_name).strip()\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "\n",
        "            return dir_name\n",
        "        else:\n",
        "            x = x + 1"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bxFQTQcGrh9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.6.3 Report-PDF"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4vZkht3grh9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_logging(setting, param, dml_param, train_loss_values, map_vals, random_map_vals, train_map, epochs,\n",
        "                   output_dir, model):\n",
        "    plot_table(setting, param, dml_param, output_dir)\n",
        "\n",
        "    gradient_visualization(model.named_parameters(), output_dir)\n",
        "    plot_loss(train_loss_values, epochs, output_dir)\n",
        "    plot_acc(map_vals, random_map_vals, train_map, epochs, output_dir)\n",
        "\n",
        "    pdfs = ['/loss.pdf', '/acc.pdf', '/params.pdf', '/dml_params.pdf', '/settings.pdf', '/gradients.pdf']\n",
        "    bookmarks = ['Loss', 'Accuracy', 'Hyperparameters', 'DML Hyperparameters', 'Seetings', 'Gradients']\n",
        "\n",
        "    merger = PdfFileMerger()\n",
        "\n",
        "    for i, pdf in enumerate(pdfs):\n",
        "        merger.append(output_dir + pdf, bookmark=bookmarks[i])\n",
        "\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Helvetica\", size=6)\n",
        "    # open the text file in read mode\n",
        "    f = open(\"log.txt\", \"r\")\n",
        "\n",
        "    # insert the texts in pdf\n",
        "    for x in f:\n",
        "        pdf.cell(200, 6, txt=x, ln=1, align='l')\n",
        "\n",
        "        # save the pdf with name .pdf\n",
        "    pdf.output(\"log.pdf\")\n",
        "    merger.append(\"log.pdf\", bookmark='Log')\n",
        "    merger.write(output_dir + \"/report.pdf\")\n",
        "    merger.close()\n",
        "\n",
        "    copyfile('log.txt', output_dir + '/log.txt')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HjdpsDjtrh9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Initialize"
      ],
      "metadata": {
        "collapsed": false,
        "id": "HONsta58rh9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Settings"
      ],
      "metadata": {
        "collapsed": false,
        "id": "nw7CU2iprh9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = Net().to(device)\n",
        "config = toml.load('./gdrive/MyDrive/mt/conf/conf.toml')\n",
        "setting = config.get('settings')\n",
        "param = config.get('params')\n",
        "dml_param = config.get('dml_params')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a7Dw5ix4rh9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. Logging"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Tb-IHEqarh9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.1. Create Dir"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3s4gTKAxrh9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "output_dir = create_output_dir(setting['output'], setting['experiment_name'])"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "97j2Bw08rh9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2. Hyperparameters"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zkjz9W7Hrh9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "batch_size_train = param['batch_size_train']\n",
        "batch_size_val = param['batch_size_val']\n",
        "lr = param['lr']\n",
        "num_epochs = param['num_epochs']"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fPkO93PXrh9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.3. Optimizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "nyBVyz7drh9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if param['optimizer'] == 'Adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "elif param['optimizer'] == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "elif param['optimizer'] == 'AdamW':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "else:\n",
        "    logger.error(' Optimizer is not supported or you have not specified one.')\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Z0hqeFGmrh9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.4. Model Architecture"
      ],
      "metadata": {
        "collapsed": false,
        "id": "RcEmcUZqrh9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if param['archi'] == 'SimpleCNN':\n",
        "    model = Net().to(device)\n",
        "\n",
        "elif param['archi'] == 'efficientnetB0':\n",
        "    model = EfficientNet.from_name('efficientnet-b0').to(device)\n",
        "\n",
        "elif param['archi'] == 'efficientnetB7':\n",
        "    model = EfficientNet.from_name('efficientnet-b7').to(device)\n",
        "    model._fc = torch.nn.Identity()\n",
        "\n",
        "elif param['archi'] == 'densenet201':\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', pretrained=False).to(device)\n",
        "    model.classifier = torch.nn.Identity()\n",
        "\n",
        "elif param['archi'] == 'ResNet':\n",
        "    model = models.resnet18(pretrained=True).to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3mVXgCQDrh9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.5. Scheduler"
      ],
      "metadata": {
        "collapsed": false,
        "id": "wNavhXVgrh9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[12], gamma=0.1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5XEBJP9Trh9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.0. PyTorch-Metric-Learning Hyperparameters"
      ],
      "metadata": {
        "collapsed": false,
        "id": "EtYEN0AMrh9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.1. Distance"
      ],
      "metadata": {
        "collapsed": false,
        "id": "uMT6SiRarh9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if dml_param['distance'] == 'CosineSimilarity':\n",
        "    distance = distances.CosineSimilarity()\n",
        "\n",
        "elif dml_param['distance'] == 'LpDistance':\n",
        "    distance = distances.LpDistance(normalize_embeddings=True, p=2, power=1)\n",
        "\n",
        "else:\n",
        "    logger.error(' Distance is not supported or you have not specified one.')\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vanj37bzrh9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.2. Reducer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Jb7HwPsUrh9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if dml_param['reducer'] == 'ThresholdReducer':\n",
        "    reducer = reducers.ThresholdReducer(low=dml_param['ThresholdReducer_low'])\n",
        "\n",
        "elif dml_param['reducer'] == 'AvgNonZeroReducer':\n",
        "    reducer = reducers.AvgNonZeroReducer()\n",
        "\n",
        "else:\n",
        "    logger.error(f'Reducer is not supported or you have not specified one.')\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "psL9eV1Nrh9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.3. Los Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "fX1311WDrh9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if dml_param['loss_function'] == 'TripletMarginLoss':\n",
        "    loss_func = losses.TripletMarginLoss(margin=dml_param['TripletMarginLoss_margin'], distance=distance,\n",
        "                                         reducer=reducer)\n",
        "\n",
        "elif dml_param['loss_function'] == 'ContrastiveLoss':\n",
        "    loss_func = losses.ContrastiveLoss(pos_margin=1, neg_margin=0)\n",
        "\n",
        "elif dml_param['loss_function'] == 'CircleLoss':\n",
        "    loss_func = losses.CircleLoss(m=dml_param['m'], gamma=dml_param['gamma'], distance=distance, reducer=reducer)\n",
        "\n",
        "else:\n",
        "    logger.error('DML Loss is not supported or you have not specified one.')\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2HkeW72jrh9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.4. Mining Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3mAhxTCkrh9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if dml_param['miner'] == 'TripletMarginMiner':\n",
        "    mining_func = miners.TripletMarginMiner(\n",
        "        margin=dml_param['TripletMarginMiner_margin'],\n",
        "        distance=distance,\n",
        "        type_of_triplets=dml_param['type_of_triplets']\n",
        "    )\n",
        "\n",
        "else:\n",
        "    logger.error('DML Miner is not supported or you have not specified one.')\n",
        "    raise ValueError()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aKboJJBnrh9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.5. Accuracy Calculator"
      ],
      "metadata": {
        "collapsed": false,
        "id": "LKhFZy-Jrh9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "accuracy_calculator = AccuracyCalculator(include=(dml_param['metric_1'],\n",
        "                                                  dml_param['metric_2']),\n",
        "                                         k=dml_param['precision_at_1_k'])"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vKDcvtp5rh9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.0.Transformations"
      ],
      "metadata": {
        "collapsed": false,
        "id": "yNqLQt6Jrh9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.1. PyTorch-Transformation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "VrDhUAQzrh9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.TenCrop((param['crop_1'], param['crop_2'])),\n",
        "    transforms.Lambda(lambda crops: torch.stack([transforms.PILToTensor()(crop) for crop in crops])),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize((param['normalize_1'], param['normalize_2'], param['normalize_3']),\n",
        "                         (param['normalize_4'], param['normalize_5'], param['normalize_6']))]\n",
        ")\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.TenCrop((param['crop_1'], param['crop_2'])),\n",
        "    transforms.Lambda(lambda crops: torch.stack([transforms.PILToTensor()(crop) for crop in crops])),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize((param['normalize_1'], param['normalize_2'], param['normalize_3']),\n",
        "                         (param['normalize_4'], param['normalize_5'], param['normalize_6']))]\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IFdfJFmIrh9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.0 Data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "vgSLu0vkrh9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4.1 Get File"
      ],
      "metadata": {
        "collapsed": false,
        "id": "sDTnI9Sjrh9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "processed_frame_train = create_processed_info(setting['path_train'])\n",
        "processed_frame_val = create_processed_info(setting['path_val'])\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kx-8SL8Zrh9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4.2 Create Dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "leM6WI4zrh9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_dataset = FAUPapyrusCollectionDataset(setting['path_train'], processed_frame_train, train_transform)\n",
        "val_dataset = FAUPapyrusCollectionDataset(setting['path_val'], processed_frame_val, val_transform)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rhreBxQerh9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4.3 Init Data Loader"
      ],
      "metadata": {
        "collapsed": false,
        "id": "xr_e-V4orh9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True, drop_last=True,\n",
        "                                           num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size_val, drop_last=True, num_workers=4)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BVLQRSQ5rh9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4.4. Create Empty Result Lists"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qBca39-xrh9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "loss_vals = []\n",
        "val_loss_vals = []\n",
        "map_vals = []\n",
        "random_map_vals = []\n",
        "train_map_vals = []"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LvkdtD8rrh9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training"
      ],
      "metadata": {
        "collapsed": false,
        "id": "nU9i_p1qrh9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Log Hyperparameters"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6OSDq6Yerh9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "logger.info(f'Debug:                {setting[\"debug\"]}')\n",
        "logger.info(f'Loos Function:        {dml_param[\"loss_function\"]}')\n",
        "logger.info(f'Margin Miner Margin:  {dml_param[\"TripletMarginMiner_margin\"]}')\n",
        "logger.info(f'Triplet Margin Loss:  {dml_param[\"TripletMarginLoss_margin\"]}')\n",
        "logger.info(f'Type of Tribles:      {dml_param[\"type_of_triplets\"]}')\n",
        "logger.info(f'Miner:                {dml_param[\"miner\"]}')\n",
        "logger.info(f'Reducer:              {dml_param[\"reducer\"]}')\n",
        "logger.info(f'Archi:                {param[\"archi\"]}')\n",
        "logger.info(f'Epochs:               {param[\"num_epochs\"]}')\n",
        "logger.info(f'Batch Size Train:     {param[\"batch_size_train\"]}')\n",
        "logger.info(f'Batch Size Val:       {param[\"batch_size_val\"]}')\n",
        "logger.info(f'Optimizer:            {param[\"optimizer\"]}')\n",
        "logger.info(f'Learning Rate:        {param[\"lr\"]}')\n",
        "logger.info(f'Shuffle:              {param[\"shuffle\"]}')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZKlbDqK0rh9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2. Train"
      ],
      "metadata": {
        "collapsed": false,
        "id": "fMDYDIF9rh9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def start_training():\n",
        "    old_map = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        ############### Training ###############\n",
        "        train_loss, train_map = train(\n",
        "            model,\n",
        "            loss_func, mining_func,\n",
        "            device,\n",
        "            train_loader,\n",
        "            optimizer,\n",
        "            train_dataset,\n",
        "            epoch,\n",
        "            accuracy_calculator,\n",
        "            scheduler,\n",
        "            accumulation_steps=param['accumulation_steps']\n",
        "        )\n",
        "\n",
        "        ############### Validation ###############\n",
        "        map, random_map = val(val_dataset, val_dataset, model, accuracy_calculator)\n",
        "\n",
        "        ############### Fill Lists ###############\n",
        "        loss_vals.append(train_loss)\n",
        "        map_vals.append(map)\n",
        "        random_map_vals.append(random_map)\n",
        "        train_map_vals.append(train_map)\n",
        "        ############### Checkpoint ###############\n",
        "\n",
        "        if map >= old_map:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': train_loss,\n",
        "            }, output_dir + \"/model.pt\")\n",
        "\n",
        "        old_map = map\n",
        "        ############### Logging ###############\n",
        "        create_logging(setting, param, dml_param, loss_vals, map_vals, random_map_vals, train_map_vals, epoch,\n",
        "                       output_dir, model)\n",
        "\n",
        "\n",
        "if setting[\"training\"]:\n",
        "    start_training()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vYDujWhwrh9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Inference\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "oHm-0xTNrh9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1. Helpers"
      ],
      "metadata": {
        "collapsed": false,
        "id": "DoVgufPvrh9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def print_decision(is_match):\n",
        "    if is_match:\n",
        "        print(\"Same class\")\n",
        "    else:\n",
        "        print(\"Different class\")\n",
        "\n",
        "\n",
        "mean = [0.6143, 0.6884, 0.7665]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-m / s for m, s in zip(mean, std)], std=[1 / s for s in std]\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Fu6RmSDHrh9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def imshow(img, figsize=(21, 9), boarder=None, get_img=False):\n",
        "    img = inv_normalize(img)\n",
        "    BLUE = [255, 0, 0]\n",
        "    npimg = img.numpy()\n",
        "    transposed = np.transpose(npimg, (1, 2, 0))\n",
        "    #boarderized = draw_border(transposed, bt=5, with_plot=False, gray_scale=False, color_name=\"red\")\n",
        "    x = int(transposed.shape[1] * 0.025)\n",
        "    y = int(transposed.shape[2] * 0.025)\n",
        "    if x > y:\n",
        "        y = x\n",
        "    else:\n",
        "        y = x\n",
        "\n",
        "    if boarder == 'green':\n",
        "        boarderized = cv2.copyMakeBorder(transposed, x, x, y, y, cv2.BORDER_CONSTANT, value=[0, 255, 0])\n",
        "    elif boarder == 'red':\n",
        "        boarderized = cv2.copyMakeBorder(transposed, x, x, y, y, cv2.BORDER_CONSTANT, value=[255, 0, 0])\n",
        "    else:\n",
        "        boarderized = transposed\n",
        "    if get_img:\n",
        "        return boarderized\n",
        "    else:\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.imshow((boarderized * 255).astype(np.uint8))\n",
        "        plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oh57Yqqwrh9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Transformations"
      ],
      "metadata": {
        "collapsed": false,
        "id": "S9Ba8qdlrh9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)]\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n_n0UfHLrh9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3. Initilize Dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "WPUXBAXgrh9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class FAUPapyrusCollectionInferenceDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"FAUPapyrusCollection dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, processed_frame, transform=None):\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.processed_frame = processed_frame\n",
        "        self.transform = transform\n",
        "        self.targets = processed_frame[\"papyID\"].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.processed_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                self.processed_frame.iloc[idx, 1])\n",
        "\n",
        "        img_name = img_name + '.png'\n",
        "\n",
        "        #image = io.imread(img_name , plugin='matploPILtlib')\n",
        "        image = PIL.Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #if False:\n",
        "        max_img_size = 2048\n",
        "\n",
        "        if (image.shape[1] > max_img_size) or (image.shape[2] > max_img_size):\n",
        "            image = transforms.CenterCrop(max_img_size)(image)\n",
        "\n",
        "        papyID = self.processed_frame.iloc[idx, 3]\n",
        "\n",
        "        return image, papyID"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hnRhDW0Krh9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class MyInferenceModel(InferenceModel):\n",
        "\n",
        "    def get_embeddings_from_tensor_or_dataset(self, inputs, batch_size):\n",
        "        inputs = self.process_if_list(inputs)\n",
        "        embeddings = []\n",
        "        if isinstance(inputs, (torch.Tensor, list)):\n",
        "            for i in range(0, len(inputs), batch_size):\n",
        "                embeddings.append(self.get_embeddings(inputs[i: i + batch_size]))\n",
        "        elif isinstance(inputs, torch.utils.data.Dataset):\n",
        "            dataloader = torch.utils.data.DataLoader(inputs, batch_size=batch_size)\n",
        "            for inp, _ in dataloader:\n",
        "                embeddings.append(self.get_embeddings(inp))\n",
        "        else:\n",
        "            raise TypeError(f\"Indexing {type(inputs)} is not supported.\")\n",
        "        return torch.cat(embeddings)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fPq8tVYlrh9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "dataset = FAUPapyrusCollectionInferenceDataset(setting['path_val'], processed_frame_val, transform)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hyf2ijElrh9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3. Get Indices"
      ],
      "metadata": {
        "collapsed": false,
        "id": "WDq38kVfrh9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_labels_to_indices(dataset):\n",
        "    labels_to_indices = {}\n",
        "    for i, sample in enumerate(dataset):\n",
        "        img, label = sample\n",
        "        if label in labels_to_indices.keys():\n",
        "            labels_to_indices[label].append(i)\n",
        "        else:\n",
        "            labels_to_indices[label] = [i]\n",
        "    return labels_to_indices"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m43z0YxWrh9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "labels_to_indices = get_labels_to_indices(dataset)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bD2HZLzlrh9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4. Load Checkpoint"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JW4mGMInrh9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = model = EfficientNet.from_name('efficientnet-b7').to(device)\n",
        "model._fc = torch.nn.Identity()\n",
        "checkpoint = torch.load(output_dir + \"/model.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "model.to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nMuy9f9irh9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5. Create Inference Model and Match Finder"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1s94Uyrrrh9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "match_finder = MatchFinder(distance=distances.CosineSimilarity(), threshold=0.2)\n",
        "inference_model = InferenceModel(model, match_finder=match_finder)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VtykDlQurh9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.6. Retrain Knn for Evaluation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lF4RndVwrh9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "inference_model.train_knn(dataset, batch_size=1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "h86BALNFrh9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infercening"
      ],
      "metadata": {
        "collapsed": false,
        "id": "BtBsOr5orh9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if setting['inference']:\n",
        "    k = 100\n",
        "\n",
        "    lowest_acc = 1\n",
        "    highest_acc = 0\n",
        "\n",
        "    temp_counter = 0\n",
        "\n",
        "    for papyID in labels_to_indices.keys():\n",
        "        if temp_counter >= 3:\n",
        "            break\n",
        "\n",
        "        for fragment in labels_to_indices[papyID]:\n",
        "            if temp_counter >= 3:\n",
        "                break\n",
        "            temp_counter = temp_counter + 1\n",
        "            img, org_label = dataset[fragment]\n",
        "            img = img.unsqueeze(0)\n",
        "            #print(f\"query image: {org_label}\")\n",
        "            #imshow(torchvision.utils.make_grid(img))\n",
        "            distances, indices = inference_model.get_nearest_neighbors(img, k=k)\n",
        "            #print(len(distances[0]))\n",
        "\n",
        "            nearest_imgs = [dataset[i][0] for i in indices.cpu()[0]]\n",
        "            #print(f\"Nearest Images:\\n\")\n",
        "\n",
        "            neighbours = []\n",
        "            labels = []\n",
        "            for i in indices.cpu()[0]:\n",
        "                neighbour, label = dataset[i]\n",
        "\n",
        "                #print(f\"Label: {label}\")\n",
        "                neighbours.append(neighbour)\n",
        "                labels.append(label)\n",
        "\n",
        "            occurrences = labels.count(org_label)\n",
        "            acc = occurrences / 100\n",
        "\n",
        "            if acc < lowest_acc:\n",
        "                lowest_acc = acc\n",
        "                print(f'Found new lowest example with acc {acc}')\n",
        "                input_img_of_lowest_acc = img\n",
        "                input_label_of_lowest_acc = org_label\n",
        "                input_index_of_lowest_acc = fragment\n",
        "                detected_neighbours_of_lowest_acc = neighbours\n",
        "                detected_labels_of_lowest_acc = labels\n",
        "                detected_distances_of_lowest_acc = distances\n",
        "\n",
        "            if acc > highest_acc:\n",
        "                highest_acc = acc\n",
        "                print(f'Found new highest example with acc {acc}')\n",
        "                input_img_of_highest_acc = img\n",
        "                input_label_of_highest_acc = org_label\n",
        "                input_index_of_highest_acc = fragment\n",
        "                detected_neighbours_of_highest_acc = neighbours\n",
        "                detected_labels_of_highest_acc = labels\n",
        "                detected_distances_of_highest_acc = distances\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cSo5s0utrh9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_inference_plot(neighbours, labels, distances, org_label, img, k, lowest):\n",
        "    if lowest:\n",
        "        print(f\"query image for lowest acc: {org_label}\")\n",
        "    else:\n",
        "        print(f\"query image for highest acc: {org_label}\")\n",
        "\n",
        "    imshow(torchvision.utils.make_grid(img))\n",
        "\n",
        "    Nr = k\n",
        "    Nc = 10\n",
        "    my_dpi = 96\n",
        "    fig, axs = plt.subplots(Nr, Nc)\n",
        "    fig.set_figheight(320)\n",
        "    fig.set_figwidth(30)\n",
        "    fig.suptitle(f'Neighbour Crops of {org_label}')\n",
        "\n",
        "    for i, neighbour in enumerate(neighbours):\n",
        "        neighbour_crops = transforms.TenCrop(32)(neighbour)\n",
        "        for j in range(Nc):\n",
        "            if j == 0:\n",
        "                distance = (distances[i].cpu().numpy().round(2))\n",
        "\n",
        "                row_label = f\"label: {labels[i]} \\n distance: {distance}\"\n",
        "                axs[i, j].set_ylabel(row_label)\n",
        "\n",
        "            neighbour_crop = neighbour_crops[j]\n",
        "            img = inv_normalize(neighbour_crop)\n",
        "            npimg = img.numpy()\n",
        "            transposed = np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "            # find right size for the frame\n",
        "            x = int(transposed.shape[1] * 0.05)\n",
        "\n",
        "            boarder = 'green'\n",
        "\n",
        "            if org_label == labels[i]:\n",
        "                boarderized = cv2.copyMakeBorder(transposed, x, x, x, x, cv2.BORDER_CONSTANT, value=[0, 1, 0])\n",
        "            elif org_label != labels[i]:\n",
        "                boarderized = cv2.copyMakeBorder(transposed, x, x, x, x, cv2.BORDER_CONSTANT, value=[1, 0, 0])\n",
        "            else:\n",
        "                boarderized = transposed\n",
        "\n",
        "            axs[i, j].imshow(boarderized, aspect='auto')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if lowest:\n",
        "        plt.savefig(\"results_for_highest_acc.pdf\", bbox_inches='tight', dpi=100)\n",
        "    else:\n",
        "        plt.savefig(\"results_for_highest_acc.pdf\", bbox_inches='tight', dpi=100)\n",
        "    plt.show()\n",
        "\n",
        "#get_inference_plot(neighbours, labels, distances[0], org_label, img, k=100)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VfLnzy-Jrh9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "if setting['inference']:\n",
        "    get_inference_plot(detected_neighbours_of_highest_acc, detected_labels_of_highest_acc,\n",
        "                       detected_distances_of_highest_acc[0], input_label_of_highest_acc, input_img_of_highest_acc,\n",
        "                       k=100, lowest=False)\n",
        "    get_inference_plot(detected_neighbours_of_lowest_acc, detected_labels_of_lowest_acc,\n",
        "                       detected_distances_of_lowest_acc[0], input_label_of_lowest_acc, input_img_of_lowest_acc, k=100,\n",
        "                       lowest=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TI58bMxgrh9R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ObVfbrVMrh9R"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "0.2.8-tb-train.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}